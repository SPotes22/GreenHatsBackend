# Chatbot orientado a facturaciÃ³n, entrenado con NLP clÃ¡sico y montado con Flask (HackatÃ³n 2025)
---
#  Chatbot Backend - PHP + OpenAI API

Este backend en **PHP** sirve como **puente entre la interfaz del chatbot y la API de OpenAI (GPT)**. Fue diseÃ±ado para procesar solicitudes de usuario y generar respuestas dinÃ¡micas cuando el modelo local no basta.

---

## Componentes

- PHP 7.4+
- cURL (para conectar con la API de OpenAI)
- Clever Cloud (hosting)
- MySQL Addon (para guardar logs y tokens)


---

## ğŸ›  Estructura Base

```
GreenHatsBackend/
â”œâ”€â”€ index.php           # Punto de entrada principal para solicitudes (API)
â”œâ”€â”€ FAQs.json           # Base de datos de preguntas frecuentes en formato JSON
â”œâ”€â”€ Dockerfile          # ConfiguraciÃ³n para contenedor Docker
â”œâ”€â”€ .dockerignore       # Archivos ignorados durante build del contenedor
â”œâ”€â”€ README.md           # DocumentaciÃ³n del backend

```

---

##  Â¿CÃ³mo funciona?

1. Recibe un `POST` con un mensaje del usuario (`question`).
2. Conecta a la API de OpenAI (`gpt-3.5-turbo`) usando cURL.
3. Devuelve una respuesta generada por el modelo.
4. (Opcional) Guarda el input/output en MySQL.

---

## ConfiguraciÃ³n de entorno

Crea un archivo `.env` con:

```dotenv
OPENAI_API_KEY=sk-xxxx
DB_HOST=localhost
DB_USER=root
DB_PASS=...
DB_NAME=chatbot_logs
```

---

##  Despliegue (Resumen de la batalla)

- Tuvimos que subir mÃºltiples versiones del backend a **Clever Cloud**, lidiando con sesiones borradas al hacer deploy.
- Usamos `.zip` para hacer actualizaciones rÃ¡pidas.
- [MicroNAS](https://github.com/SPotes22/MicroNAS-Flask) se usÃ³ como servidor de respaldo con acceso fÃ­sico.
- El sistema de tokens se rompiÃ³ durante el pitch por consumo excesivo â†’ âš ï¸ *usar cache o backup model next time*.

---

## ğŸ“¡ Endpoints

- `POST /index.php`
  - Body: `{ "question": "Â¿CÃ³mo veo mi factura?" }`
  - Header: `Content-Type: application/json`
  - Respuesta: `"Puedes ver tu factura en el portal de clientes..."`

---

##  Lecciones

- Clever Cloud borra sesiÃ³n en cada deploy â†’ usar archivos persistentes.
- Los tokens de OpenAI tienen lÃ­mite â†’ usar fallback local o caching.
- El tiempo de build puede matar el pitch â†’ **tener siempre un mock o respuesta guardada**.

---

##  Autores

Hecho con demasiada cafeÃ­na y resiliencia por:

- Santiago Potes Giraldo
- Juan Franco
- Freddy Alejandro Aristizabal

---

## ğŸ“œ Licencia

MIT â€” ForkÃ©alo, rÃ³mpelo, mejÃ³ralo.
